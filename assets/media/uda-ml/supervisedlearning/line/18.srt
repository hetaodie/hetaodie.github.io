1
00:00:00,000 --> 00:00:03,779
那么这里有解决非线性数据的另一种方法

2
00:00:03,779 --> 00:00:06,240
我们需要使用分段线性函数

3
00:00:06,240 --> 00:00:09,919
相当于几条直线连接起来 较好地拟合数据

4
00:00:09,919 --> 00:00:14,219
那么我们如何做到呢？ 它对我们来说已经不陌生了 神经网络

5
00:00:14,220 --> 00:00:16,530
这里是一个用于分类的神经网络例子

6
00:00:16,530 --> 00:00:20,054
包含 n 个输入和一些偏置单元

7
00:00:20,054 --> 00:00:23,429
和一批 ReLu 激活函数

8
00:00:23,429 --> 00:00:25,344
最后你可以看到一个 Sigmod 函数

9
00:00:25,344 --> 00:00:28,349
这是因为我们使用神经网络进行分类

10
00:00:28,350 --> 00:00:32,344
所以我们得到的最终答案是 0 到 1 之间的数字

11
00:00:32,344 --> 00:00:34,295
但是如果我们使用神经网络

12
00:00:34,295 --> 00:00:36,480
并不是为了分类 而是为了回归 应该怎么办呢？

13
00:00:36,479 --> 00:00:38,694
我们不想得到 0 到 1 之间的数字

14
00:00:38,695 --> 00:00:41,030
而是希望得到任何数字

15
00:00:41,030 --> 00:00:43,195
让我给你展示一个非常简单的技巧

16
00:00:43,195 --> 00:00:46,230
实际上你只需要删除最后一个 sigmoid 单元

17
00:00:46,229 --> 00:00:49,709
就可以返回你之前得到的值

18
00:00:49,710 --> 00:00:55,405
这个值是前面各层的输出加权总和 就是这样

19
00:00:55,405 --> 00:00:56,770
为了训练这个网络

20
00:00:56,770 --> 00:00:58,905
我们可以使用不同的误差或损失函数

21
00:00:58,905 --> 00:01:01,995
这就成为我们看到的这部分 给定均方误差函数

22
00:01:01,994 --> 00:01:06,469
或标签与预测之间的方差

23
00:01:06,469 --> 00:01:09,287
即 (y-y-hat)²

24
00:01:09,287 --> 00:01:12,660
当然 我们也可以增加这个 或对所有点求平均值

25
00:01:12,659 --> 00:01:15,689
但是大体来说 如果我们使用这个函数 结合反向传播

26
00:01:15,689 --> 00:01:19,894
我们能够像分类一样训练我们的神经网络

27
00:01:19,894 --> 00:01:22,667
这就是我绘制的脑海中神经网络回归

28
00:01:22,667 --> 00:01:25,530
在隐藏层 我们有一些线性函数和输入

29
00:01:25,530 --> 00:01:28,349
分别是 X 和偏置单元 1

30
00:01:28,349 --> 00:01:31,079
这些线性函数只是直线

31
00:01:31,079 --> 00:01:32,320
然后我们将它们与 ReLu 结合起来

32
00:01:32,320 --> 00:01:35,069
把它们与 ReLu 结合起来 是通过

33
00:01:35,069 --> 00:01:39,169
把直线的负值或位于 X 轴下方的部分转变为 0

34
00:01:39,170 --> 00:01:40,560
现在下一层只是求出

35
00:01:40,560 --> 00:01:44,165
这些线性函数与 ReLu 结合后的线性组合

36
00:01:44,165 --> 00:01:46,109
这就是线性组合的样子

37
00:01:46,109 --> 00:01:48,179
看起来像是分段线性函数

38
00:01:48,180 --> 00:01:51,633
我们在这里也可以使用 sigmoid 或 TanH 等其他激活函数

39
00:01:51,632 --> 00:01:53,064
我们依然使用反向传播训练这些函数

40
00:01:53,064 --> 00:01:55,709
最小化均方误差

41
00:01:55,709 --> 00:01:58,199
这些网络看起来会是这样

42
00:01:58,200 --> 00:02:02,549
当你把线性函数和 sigmoid 结合起来 得到线性组合

43
00:02:02,549 --> 00:02:04,560
所以总体来说 这是个振奋人心的消息

44
00:02:04,560 --> 00:02:07,695
这就意味着我们可以使用神经网络 并不是为了分类

45
00:02:07,694 --> 00:02:08,930
而是为了回归

46
00:02:08,930 --> 00:02:11,530
只需要删除最后一个激活函数即可

