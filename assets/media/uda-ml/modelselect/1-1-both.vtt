WEBVTT

1
00:00:00.150 --> 00:00:01.690
So let's talk about life.

2
00:00:00.150 --> 00:00:01.690
我们来聊聊实际生活的例子

3
00:00:01.690 --> 00:00:04.445
有时我们在生活中会犯两种错误

4
00:00:01.690 --> 00:00:04.445
There are two errors that
sometimes we make in life.

5
00:00:04.445 --> 00:00:08.019
第一种是用苍蝇拍来杀死哥斯拉龙

6
00:00:04.445 --> 00:00:08.019
One is trying to kill
Godzilla with a flyswatter.

7
00:00:08.019 --> 00:00:09.959
That's a pretty bad error to make.

8
00:00:08.019 --> 00:00:09.959
这是非常愚蠢的错误

9
00:00:09.960 --> 00:00:13.260
它过度简化了我们要解决的问题

10
00:00:09.960 --> 00:00:13.260
It's oversimplifying the problem
we're trying to solve.

11
00:00:13.259 --> 00:00:15.960
The other one is to try to
kill a fly with a bazooka.

12
00:00:13.259 --> 00:00:15.960
另一种是用火箭筒杀死苍蝇

13
00:00:15.960 --> 00:00:17.269
这也非常不实际

14
00:00:15.960 --> 00:00:17.269
That's also pretty bad.

15
00:00:17.269 --> 00:00:20.579
It's overcomplicating the problem
we're trying to solve.

16
00:00:17.269 --> 00:00:20.579
它过度复杂化了我们要解决的问题

17
00:00:20.579 --> 00:00:25.139
在机器学习中 我们也非常容易犯这两种错误

18
00:00:20.579 --> 00:00:25.139
In machine learning, these two types
of errors are very easy to make.

19
00:00:25.140 --> 00:00:28.929
当我们过度简化问题时 我们称之为欠拟合

20
00:00:25.140 --> 00:00:28.929
When we oversimplify the problem,
we call this underfitting.

21
00:00:28.929 --> 00:00:33.090
过度复杂化时 称之为过拟合

22
00:00:28.929 --> 00:00:33.090
And when we overcomplicate the problem,
we call it overfitting.

23
00:00:33.090 --> 00:00:36.175
我们更详细地认识一下过拟合和欠拟合

24
00:00:33.090 --> 00:00:36.175
So let's look at underfitting and
overfitting in a bit more detail.

25
00:00:36.174 --> 00:00:38.484
先看这样一个分类问题

26
00:00:36.174 --> 00:00:38.484
Let's look at this
classification problem.

27
00:00:38.484 --> 00:00:42.015
We need to find a property that
separates the set on the left

28
00:00:38.484 --> 00:00:42.015
我们需要找到一个属性 将左边的集合

29
00:00:42.015 --> 00:00:43.994
与右边的集合分开

30
00:00:42.015 --> 00:00:43.994
from the set on the right.

31
00:00:43.994 --> 00:00:45.744
看起来解决方法很简单

32
00:00:43.994 --> 00:00:45.744
It seems like the solution is easy.

33
00:00:45.744 --> 00:00:47.784
右边的集合元素都是狗

34
00:00:45.744 --> 00:00:47.784
The set on the right is made of dogs,
and

35
00:00:47.784 --> 00:00:51.214
the set on the left is made
of things that are not dogs.

36
00:00:47.784 --> 00:00:51.214
左边的集合元素都不是

37
00:00:51.215 --> 00:00:53.015
如果我们过度简化它会怎样？

38
00:00:51.215 --> 00:00:53.015
But what if we oversimplify this?

39
00:00:53.015 --> 00:00:56.314
假如我们说右边的都是动物

40
00:00:53.015 --> 00:00:56.314
What if we say the set on
the right is made of animals, and

41
00:00:56.314 --> 00:00:58.724
而左边的都不是动物

42
00:00:56.314 --> 00:00:58.724
the set on the left is made
of everything but animals?

43
00:00:58.725 --> 00:01:00.770
Then our model is is a bit too simple.

44
00:00:58.725 --> 00:01:00.770
那么我们的模型就太简单了

45
00:01:00.770 --> 00:01:04.542
而且可以看出我们已在训练集中犯了一个错误

46
00:01:00.770 --> 00:01:04.542
And we can see that it already makes
a mistake on the training set,

47
00:01:04.542 --> 00:01:07.433
since it misclassified
this cat on the left side.

48
00:01:04.542 --> 00:01:07.433
因为猫被错误地分类到了左边

49
00:01:07.433 --> 00:01:10.566
这种过度简化成为欠拟合

50
00:01:07.433 --> 00:01:10.566
This oversimplification
is called underfitting.

51
00:01:10.566 --> 00:01:14.920
One characteristic of it is that it
doesn't do well on the training set.

52
00:01:10.566 --> 00:01:14.920
它的一个特点是训练集的拟合不够好

53
00:01:14.920 --> 00:01:18.519
我们称这种类型为偏差引起的误差

54
00:01:14.920 --> 00:01:18.519
We call this type of error
an error due to bias.

55
00:01:18.519 --> 00:01:21.629
The other mistake we can make
is to overcomplicate the model.

56
00:01:18.519 --> 00:01:21.629
我们会犯的另一个错误是过度复杂化模型

57
00:01:21.629 --> 00:01:25.479
If instead of describing the set on
the right as dogs, we describe it as

58
00:01:21.629 --> 00:01:25.479
这次我们不将右边的集合描述为狗

59
00:01:25.480 --> 00:01:28.920
dogs that are wagging their tail,
then this seems to do the job well in

60
00:01:25.480 --> 00:01:28.920
而是摇着尾巴的狗 这看起来在训练集中

61
00:01:28.920 --> 00:01:33.439
的拟合效果会很好 但直觉告诉我们这样做不对

62
00:01:28.920 --> 00:01:33.439
training set, but somehow our intuition
is telling us that this is not right.

63
00:01:33.439 --> 00:01:35.890
在出现一个新实例时你就明白了

64
00:01:33.439 --> 00:01:35.890
This can be confirmed when
you bring out a new instance.

65
00:01:35.890 --> 00:01:38.469
For example, this dog over here.

66
00:01:35.890 --> 00:01:38.469
例如这里这只狗

67
00:01:38.469 --> 00:01:42.129
Our logic tells us this dog should
belong to the set on the right.

68
00:01:38.469 --> 00:01:42.129
逻辑告诉我们这只狗应该属于右边的集合

69
00:01:42.129 --> 00:01:44.381
但由于这只狗没有摇尾巴

70
00:01:42.129 --> 00:01:44.381
But since the dog is
not wagging its tail,

71
00:01:44.381 --> 00:01:47.868
此模型会错误地将它分类到左边的集合

72
00:01:44.381 --> 00:01:47.868
then this model mistakenly classifies
it in the set on the left.

73
00:01:47.868 --> 00:01:52.920
此错误称为过拟合 也就是说此模型太过具体

74
00:01:47.868 --> 00:01:52.920
This error is called overfitting,
this means the model is too specific.

75
00:01:52.920 --> 00:01:57.070
它的一个特点是它在训练集中表现良好

76
00:01:52.920 --> 00:01:57.070
One characteristic of it is that it
does well in the training set but

77
00:01:57.069 --> 00:02:00.639
但它趋向于记住而不是学习数据的特点

78
00:01:57.069 --> 00:02:00.639
it tends to memorize it instead of
learning the characteristics of it, so

79
00:02:00.640 --> 00:02:02.980
it will not do well on the testing set.

80
00:02:00.640 --> 00:02:02.980
因此在测试集上的表现不好

81
00:02:02.980 --> 00:02:05.890
We call this type of error
an error due to variance.

82
00:02:02.980 --> 00:02:05.890
我们称这种错误为方差引起的误差

83
00:02:05.890 --> 00:02:07.079
从技术层面来说

84
00:02:05.890 --> 00:02:07.079
Let's get more technical.

85
00:02:07.079 --> 00:02:10.210
在回归示例中 可以看到下面这样的欠拟合

86
00:02:07.079 --> 00:02:10.210
In our regression example,
we can see underfitting as follows.

87
00:02:10.210 --> 00:02:12.170
看看左边的点

88
00:02:10.210 --> 00:02:12.170
Let's look at the points on the left.

89
00:02:12.169 --> 00:02:13.659
看起来这些点的正确模型

90
00:02:12.169 --> 00:02:13.659
It seems like the correct model for

91
00:02:13.659 --> 00:02:16.310
this point is a quadratic
equation like this one.

92
00:02:13.659 --> 00:02:16.310
是像这样的二次方程

93
00:02:16.310 --> 00:02:19.259
We could try to model it as a line,
but this won't work too well,

94
00:02:16.310 --> 00:02:19.259
我们可以尝试将它拟合成一条直线 但效果不太好

95
00:02:19.259 --> 00:02:21.019
因为它太简单了

96
00:02:19.259 --> 00:02:21.019
since it's too simple.

97
00:02:21.020 --> 00:02:23.540
此模型在训练集上的效果不好

98
00:02:21.020 --> 00:02:23.540
The model won't do well
in our training set.

99
00:02:23.539 --> 00:02:25.849
这是欠拟合的示例

100
00:02:23.539 --> 00:02:25.849
This is an example of underfitting.

101
00:02:25.849 --> 00:02:29.469
Now, what if instead we try to
fit a polynomial of large degree

102
00:02:25.849 --> 00:02:29.469
那么 如果我们尝试拟合一个大角度的多项式呢

103
00:02:29.469 --> 00:02:30.349
就像这一个？

104
00:02:29.469 --> 00:02:30.349
like this one?

105
00:02:30.349 --> 00:02:34.289
这个多项式在训练集上的表现很好 完美拟合了点

106
00:02:30.349 --> 00:02:34.289
This polynomial does great in
the training set, fits it perfectly, but

107
00:02:34.289 --> 00:02:36.979
somehow it seems like
it's not the best answer.

108
00:02:34.289 --> 00:02:36.979
但它似乎并非最佳答案

109
00:02:36.979 --> 00:02:40.679
It memorizes the training set and
it fails to find good properties of

110
00:02:36.979 --> 00:02:40.679
它记住了训练集 但未能找到训练集的

111
00:02:40.680 --> 00:02:43.819
良好属性 以很好地泛化到测试集

112
00:02:40.680 --> 00:02:43.819
the training set that will
generalize well to the testing set.

113
00:02:43.819 --> 00:02:46.550
So even though it performs
well in the training set,

114
00:02:43.819 --> 00:02:46.550
所以即使它在训练集上的表现很好

115
00:02:46.550 --> 00:02:48.795
it will perform poorly
on the testing set.

116
00:02:46.550 --> 00:02:48.795
但在测试集上的效果会很差

117
00:02:48.795 --> 00:02:50.919
This is an example of overfitting.

118
00:02:48.795 --> 00:02:50.919
这是过拟合的例子

119
00:02:50.919 --> 00:02:53.459
我们也会在分类模型中看到欠拟合

120
00:02:50.919 --> 00:02:53.459
We can see underfitting in
a classification model as well.

121
00:02:53.460 --> 00:02:53.820
The red and

122
00:02:53.460 --> 00:02:53.820
在这里 红色点

123
00:02:53.819 --> 00:02:57.989
blue points seems to be nicely separated
by a quadratic curve like this one.

124
00:02:53.819 --> 00:02:57.989
和蓝色点似乎很好地被这条二次曲线分隔开了

125
00:02:57.990 --> 00:03:01.320
如果我们用直线的话 此模型不能正确地拟合点

126
00:02:57.990 --> 00:03:01.320
When we try to use a line, the model
doesn't fit the points properly, and

127
00:03:01.319 --> 00:03:02.668
it underfits.

128
00:03:01.319 --> 00:03:02.668
会出现欠拟合

129
00:03:02.668 --> 00:03:05.830
如果我们尝试拟合到非常复杂的曲线

130
00:03:02.668 --> 00:03:05.830
And when we try to fit in a curve
that is very complicated,

131
00:03:05.830 --> 00:03:08.570
we end up with a model
that is too complex.

132
00:03:05.830 --> 00:03:08.570
最终会得到一个太过复杂的模型

133
00:03:08.569 --> 00:03:11.099
它在测试集上的效果会很差

134
00:03:08.569 --> 00:03:11.099
And this may not do well
in the testing set.

135
00:03:11.099 --> 00:03:13.340
会出现过拟合

136
00:03:11.099 --> 00:03:13.340
Thus it overfits.

137
00:03:13.340 --> 00:03:14.700
So here's a small summary.

138
00:03:13.340 --> 00:03:14.700
那么我们简单总结一下

139
00:03:14.699 --> 00:03:18.539
一方面 我们获得高偏差误差或欠拟合

140
00:03:14.699 --> 00:03:18.539
On one side, we get the errors due
to high bias, or underfitting.

141
00:03:18.539 --> 00:03:20.329
This is where we
oversimplify the problem and

142
00:03:18.539 --> 00:03:20.329
这里我们过度简化了问题

143
00:03:20.330 --> 00:03:23.890
our model is too simple to capture
the complexity of our data.

144
00:03:20.330 --> 00:03:23.890
我们的模型太简单 无法捕捉到数据的复杂性

145
00:03:23.889 --> 00:03:28.509
On the other side, we get the errors
due to high variance or overfitting.

146
00:03:23.889 --> 00:03:28.509
另一方面 我们获得高方差误差或过拟合

147
00:03:28.509 --> 00:03:32.850
This is when we overcomplicate the
problem and our model is too complex and

148
00:03:28.509 --> 00:03:32.850
我们在这里过度复杂化了问题 我们的模型太复杂

149
00:03:32.850 --> 00:03:35.937
ends up memorizing our data
instead of learning it.

150
00:03:32.850 --> 00:03:35.937
以至于记住了数据 而非学习了它

151
00:03:35.937 --> 00:03:38.401
Then in the middle,
we've got the good model.

152
00:03:35.937 --> 00:03:38.401
而中间的是最佳模型

153
00:03:38.401 --> 00:03:40.022
When it comes to the training data,

154
00:03:38.401 --> 00:03:40.022
在训练数据方面

155
00:03:40.022 --> 00:03:43.849
高偏差模型因为太简单而欠拟合

156
00:03:40.022 --> 00:03:43.849
the high bias model tends to not fit it
well since it's just too simple a model.

157
00:03:43.849 --> 00:03:46.840
高方差模型趋向于完美拟合训练数据

158
00:03:43.849 --> 00:03:46.840
The high variance model tends to
fit the training data really well

159
00:03:46.840 --> 00:03:48.259
因为它完全匹配了每个点

160
00:03:46.840 --> 00:03:48.259
since it's designed for it.

161
00:03:48.259 --> 00:03:51.219
Finally, the good model tends
to fit the training data well.

162
00:03:48.259 --> 00:03:51.219
最终 最佳模型对训练数据的拟合刚刚好

163
00:03:51.219 --> 00:03:53.250
Now, when it comes to the testing data,

164
00:03:51.219 --> 00:03:53.250
然后 在测试数据方面

165
00:03:53.250 --> 00:03:56.050
the high bias model
tends to perform poorly.

166
00:03:53.250 --> 00:03:56.050
高偏差模型的效果会很差

167
00:03:56.050 --> 00:03:58.027
高方差模型也是

168
00:03:56.050 --> 00:03:58.027
And so does the high variance model.

169
00:03:58.026 --> 00:04:00.829
The good model is the one that
performs well in the testing data.

170
00:03:58.026 --> 00:04:00.829
而最佳模型在测试数据上的效果较好

