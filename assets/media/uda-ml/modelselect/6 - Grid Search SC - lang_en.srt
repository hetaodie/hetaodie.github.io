1
00:00:00,000 --> 00:00:02,560
So here's a summary of what we do in machine learning.

2
00:00:02,560 --> 00:00:05,580
First, we train a bunch of models with our training data.

3
00:00:05,580 --> 00:00:09,589
Then, we use a cross-validation data to pick the best of these models.

4
00:00:09,589 --> 00:00:13,144
And finally, we test it with the testing data to make sure our model is good.

5
00:00:13,144 --> 00:00:16,239
So here's an example of training a logistic regression model.

6
00:00:16,239 --> 00:00:18,274
Let's say, we have four candidates,

7
00:00:18,274 --> 00:00:19,964
we train a model of degree one,

8
00:00:19,964 --> 00:00:24,425
which is a line and one of degree two, three, and four.

9
00:00:24,425 --> 00:00:26,190
We train them with the training data to find

10
00:00:26,190 --> 00:00:29,130
the slope and the coefficients of the polynomials et cetera.

11
00:00:29,129 --> 00:00:34,564
Then we use the cross-validation data to calculate say the F1 score of all these models.

12
00:00:34,564 --> 00:00:38,259
And then, we pick the model with the highest F1 score.

13
00:00:38,259 --> 00:00:42,570
As a final step, we use our testing data to make sure our model is good.

14
00:00:42,570 --> 00:00:46,259
So the parameters of the algorithm in this case are the coefficients

15
00:00:46,259 --> 00:00:50,189
of the polynomial but the degree of the polynomial is like a matter parameter.

16
00:00:50,189 --> 00:00:52,859
We call those hyper parameters.

17
00:00:52,859 --> 00:00:54,089
Let's see another example. Let's say,

18
00:00:54,090 --> 00:00:55,580
we're training a decision tree.

19
00:00:55,579 --> 00:00:57,390
So what are the hyper parameters?

20
00:00:57,390 --> 00:01:00,615
Well, one of them is depth. Let's say we have one of depth one,

21
00:01:00,615 --> 00:01:02,825
two, three, and four.

22
00:01:02,825 --> 00:01:06,765
We use the training data to train a bunch of trees of depth one,

23
00:01:06,765 --> 00:01:09,420
two, three, and four.

24
00:01:09,420 --> 00:01:13,519
So the parameters here are the thresholds in the leaves and the nodes et cetera.

25
00:01:13,519 --> 00:01:16,259
Then, we take the F1 score and calculate it on

26
00:01:16,260 --> 00:01:19,805
the cross-validation set on each of these models.

27
00:01:19,805 --> 00:01:22,235
Then we pick the one that did the best.

28
00:01:22,234 --> 00:01:23,834
And finally, with the testing set,

29
00:01:23,834 --> 00:01:25,539
we make sure this model is good.

30
00:01:25,540 --> 00:01:28,475
So what happens if we have more than one hyper parameter?

31
00:01:28,474 --> 00:01:31,069
Here we only have one which is depth.

32
00:01:31,069 --> 00:01:33,479
What if we're training a support vector machine?

33
00:01:33,480 --> 00:01:35,820
So in an SVM, we as we have some hyper parameters like

34
00:01:35,819 --> 00:01:38,759
the kernel which can be linear or polynomial, for example.

35
00:01:38,760 --> 00:01:40,620
And we also have the gamma parameter,

36
00:01:40,620 --> 00:01:43,430
which if it's small, gives a solutions like this.

37
00:01:43,430 --> 00:01:44,670
And if it's large,

38
00:01:44,670 --> 00:01:46,750
It gives a solution like that.

39
00:01:46,750 --> 00:01:51,135
So how do we pick the best combination between kernel and gamma?

40
00:01:51,135 --> 00:01:55,365
Well, very simple, it's called grid search and it literally just says

41
00:01:55,364 --> 00:01:58,809
make a table with all the possibilities and pick the best one.

42
00:01:58,810 --> 00:02:02,469
Our columns here are the different kernels we can use, linear and polynomial.

43
00:02:02,469 --> 00:02:05,189
And the rows are the different values of gamma.

44
00:02:05,189 --> 00:02:09,599
It's recommended to take a few values that grow exponentially such as 0.1,

45
00:02:09,599 --> 00:02:13,185
1, 10, 100, 1000, etc.

46
00:02:13,185 --> 00:02:15,870
So again, we use our training set to train a bunch of

47
00:02:15,870 --> 00:02:19,509
linear models and polynomial models with different values of gamma.

48
00:02:19,509 --> 00:02:24,269
Then we use the cross validation set to calculate the F1 score on all these models.

49
00:02:24,270 --> 00:02:28,305
And then we simply pick the one with the highest F1 score.

50
00:02:28,305 --> 00:02:33,420
And finally, we use a testing set to make sure that what we did was good.

