1
00:00:00,120 --> 00:00:03,550
最后 我们学习一个非常有用的循环利用数据的方法

2
00:00:03,549 --> 00:00:06,279
称为 k 折交叉验证

3
00:00:06,280 --> 00:00:10,080
如之前所学 我们将数据分为训练集和测试集

4
00:00:10,080 --> 00:00:11,300
来进行测试

5
00:00:11,300 --> 00:00:14,679
但这并不总是理想的做法 因为我们似乎会扔掉一些

6
00:00:14,679 --> 00:00:17,259
对训练我们的算法有用的数据

7
00:00:17,260 --> 00:00:20,070
那么有办法可以让我们不用扔掉这些数据

8
00:00:20,070 --> 00:00:22,089
而同时又不用作弊吗？

9
00:00:22,089 --> 00:00:23,289
这里有一个解决方法

10
00:00:23,289 --> 00:00:25,809
也是 K 折交叉验证派上用场的时候

11
00:00:26,850 --> 00:00:30,850
在 K 折交叉验证中 我们将数据分为 K 个包

12
00:00:30,850 --> 00:00:32,859
在这个例子中 K 等于 4

13
00:00:32,859 --> 00:00:35,979
然后我们将模型培训 K 次

14
00:00:35,979 --> 00:00:39,619
每次将不同的包用作测试集

15
00:00:39,619 --> 00:00:43,030
而剩下的点作为训练集

16
00:00:43,030 --> 00:00:46,520
然后我们求结果的平均值 来得到最终模型

17
00:00:46,520 --> 00:00:49,280
在 sklearn 中执行此操作的命令非常简单

18
00:00:49,280 --> 00:00:52,420
我们要做的就是创建一个 KFold 对象

19
00:00:52,420 --> 00:00:56,469
其中参数为数据的大小和测试集的大小

20
00:00:56,469 --> 00:01:00,649
始终建议随机化我们的数据 以消除任何可能的偏差

21
00:01:00,649 --> 00:01:02,850
这里我们仍然将数据拆分为包

22
00:01:02,850 --> 00:01:05,900
但是是随机而非顺序选择

23
00:01:05,900 --> 00:01:08,760
在 sklearn 中进行随机化也很容易 只需

24
00:01:08,760 --> 00:01:12,980
在初始化 KFold 对象时将 shuffle 参数设为 true 即可

