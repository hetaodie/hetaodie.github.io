1
00:00:00,000 --> 00:00:05,200
Now that was when we had two classes namely receiving a gift or not receiving a gift.

2
00:00:05,200 --> 00:00:09,269
What happens if we have more classes? Let's take a look.

3
00:00:09,269 --> 00:00:10,769
So, we have a similar problem.

4
00:00:10,769 --> 00:00:14,625
We still have three doors and this problem is still not the Monty Hall problem.

5
00:00:14,625 --> 00:00:19,118
Behind each door there can be an animal and the animal can be of three types;

6
00:00:19,117 --> 00:00:20,384
it can be a duck,

7
00:00:20,385 --> 00:00:21,554
it can be a beaver,

8
00:00:21,553 --> 00:00:23,570
or it can be a walrus.

9
00:00:23,570 --> 00:00:26,149
So, let's look at this table of probabilities.

10
00:00:26,149 --> 00:00:28,469
According to the first column in the table,

11
00:00:28,469 --> 00:00:30,120
behind the first door,

12
00:00:30,120 --> 00:00:33,039
the probability of finding a duck is 0.7,

13
00:00:33,039 --> 00:00:39,390
the probability of finding a beaver is 0.2 and the probability finding a walrus is 0.1.

14
00:00:39,390 --> 00:00:42,140
Notice that the numbers in each column need to add (up) to

15
00:00:42,140 --> 00:00:45,750
1 because there is some animal behind door 1.

16
00:00:45,750 --> 00:00:49,695
The numbers in the rows do not need to add (up) to 1 as you can see.

17
00:00:49,695 --> 00:00:53,719
It could easily be that we have a duck behind every door and that's okay.

18
00:00:53,719 --> 00:00:55,670
So, let's look at a sample scenario.

19
00:00:55,670 --> 00:00:59,789
Let's say we have our three doors and behind the first door, there's a duck;

20
00:00:59,789 --> 00:01:02,024
behind the second door, there's a walrus;

21
00:01:02,024 --> 00:01:03,329
and behind the third door,

22
00:01:03,329 --> 00:01:05,099
there's also a walrus.

23
00:01:05,099 --> 00:01:08,185
Recall that the probabilities are given by the table.

24
00:01:08,185 --> 00:01:11,524
So, a duck behind the first door is 0.7 likely,

25
00:01:11,524 --> 00:01:14,299
a walrus behind the second door is 0.3

26
00:01:14,299 --> 00:01:18,900
likely and a walrus behind the third door is 0.4 likely.

27
00:01:18,900 --> 00:01:21,159
So, the probability of obtaining these three animals is

28
00:01:21,159 --> 00:01:23,590
the product of the probabilities of the three events,

29
00:01:23,590 --> 00:01:25,439
since they are independent events,

30
00:01:25,438 --> 00:01:29,233
which in this case, it's 0.084.

31
00:01:29,233 --> 00:01:32,608
And as we learn, the cross-entropy here is

32
00:01:32,608 --> 00:01:37,098
given by the sums of the negatives of the logarithms of the probabilities.

33
00:01:37,099 --> 00:01:40,715
So the first one is negative logarithm 0.7.

34
00:01:40,715 --> 00:01:43,424
The second one is negative logarithm 0.3,

35
00:01:43,424 --> 00:01:46,609
and the third one is negative logarithm of 0.4.

36
00:01:46,608 --> 00:01:49,679
The cross-entropies and the sum of these three,

37
00:01:49,680 --> 00:01:52,760
which is actually 2.48.

38
00:01:52,760 --> 00:01:55,681
But we want a formula, so let's put some variables here.

39
00:01:55,680 --> 00:01:59,438
So, P11 is the probability of finding a duck behind door one;

40
00:01:59,438 --> 00:02:04,544
P12 is the probability of finding a duck behind door two, etc.

41
00:02:04,545 --> 00:02:09,699
And let's have the indicator variables: y1j be 1 if there's a duck

42
00:02:09,699 --> 00:02:14,659
behind door j. y2j be 1 if there's a beaver behind door j;

43
00:02:14,658 --> 00:02:18,984
and y3j be 1 if there is a walrus behind door j.

44
00:02:18,985 --> 00:02:21,960
And these variables are zero otherwise.

45
00:02:21,960 --> 00:02:24,860
And so, the formula for the cross-entropy is simply the

46
00:02:24,860 --> 00:02:28,310
negative of the summation from i= 1 to n,

47
00:02:28,310 --> 00:02:35,930
up to summation from y = j to m of y_i_j times the logarithm of p_i_j.

48
00:02:35,930 --> 00:02:39,110
In this case, n is the number of classes.

49
00:02:39,110 --> 00:02:43,610
This formula works because the y_i_j being 01 made sure that we're

50
00:02:43,610 --> 00:02:45,289
only adding the logarithms of

51
00:02:45,288 --> 00:02:48,543
the probabilities of the events that actually have occurred.

52
00:02:48,544 --> 00:02:53,750
And voila. This is the formula for the cross-entropy in more classes.

53
00:02:53,750 --> 00:02:56,389
Now, I'm going to leave you with a question: given that we have a formula for

54
00:02:56,389 --> 00:02:59,776
cross-entropy for two classes and one for m classes,

55
00:02:59,776 --> 00:03:04,335
these formulas look different but are they the same for m=2?

56
00:03:04,335 --> 00:03:05,555
Obviously, the answer is yes,

57
00:03:05,555 --> 00:03:07,938
but it's a cool exercise to actually write them down and

58
00:03:07,938 --> 00:03:11,000
convince yourself that they are actually the same.

