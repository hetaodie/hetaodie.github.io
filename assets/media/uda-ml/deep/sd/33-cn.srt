1
00:00:00,000 --> 00:00:03,720
我们从数学的角度来具体学习梯度下降

2
00:00:03,720 --> 00:00:07,830
误差函数是关于权重的函数 它可以绘制成（上图）这样

3
00:00:07,830 --> 00:00:09,615
现在我们有了数学上的结构

4
00:00:09,615 --> 00:00:11,250
所以现在它不再是误差之巅

5
00:00:11,250 --> 00:00:13,835
更像是误差山脉 （译者注：与 “马特洪峰” 音近）

6
00:00:13,835 --> 00:00:18,379
我们站在山脉中的某个位置 需要下去

7
00:00:18,379 --> 00:00:22,019
函数输入是 W1 和 W2

8
00:00:22,018 --> 00:00:25,827
误差函数是 E

9
00:00:25,829 --> 00:00:29,469
E 的梯度是

10
00:00:29,469 --> 00:00:35,140
E 相对于 W1 和 W2 偏导数的矢量和

11
00:00:35,140 --> 00:00:38,140
这个梯度实际上告诉了我们

12
00:00:38,140 --> 00:00:42,689
误差函数增长最快的方向

13
00:00:42,689 --> 00:00:45,908
因此 如果沿着该梯度的反方向

14
00:00:45,908 --> 00:00:48,985
将得到误差函数降低最快的方向

15
00:00:48,987 --> 00:00:51,158
这也正是我们想得到的

16
00:00:51,158 --> 00:00:52,890
在我们站着的地方

17
00:00:52,890 --> 00:00:59,048
计算该位置误差函数的梯度

18
00:00:59,048 --> 00:01:01,243
然后朝着梯度的反方向前进一步

19
00:01:01,243 --> 00:01:06,599
这样使我们的位置降低了一些

20
00:01:06,599 --> 00:01:12,915
然后不断重复上述步骤 直到抵达山脚

21
00:01:12,915 --> 00:01:15,180
所以我们是这么计算梯度的

22
00:01:15,180 --> 00:01:20,010
从初始预测 y=σ(WX+b) 开始

23
00:01:20,010 --> 00:01:22,079
这个预测不太准确

24
00:01:22,078 --> 00:01:24,567
我们站在山脉的高处 也就是误差很大

25
00:01:24,569 --> 00:01:26,879
预测公式是这样的

26
00:01:26,879 --> 00:01:33,694
y=σ(W1X1+...+WnXn+b)

27
00:01:33,694 --> 00:01:36,079
误差函数是我们之前见到的公式

28
00:01:36,078 --> 00:01:40,487
但重要的是误差函数的梯度

29
00:01:40,489 --> 00:01:44,900
误差函数的梯度就是

30
00:01:44,900 --> 00:01:50,180
误差函数相对权重和偏差的偏导数所组成的矢量

31
00:01:50,180 --> 00:01:53,821
我们沿着梯度的反方向前进一步

32
00:01:53,819 --> 00:01:57,767
和之前一样 我们不希望做出剧烈的变化

33
00:01:57,769 --> 00:02:01,234
我们将引入更小的学习速率

34
00:02:01,233 --> 00:02:06,000
例如等于 0.1 我们将用梯度乘以这个数字

35
00:02:06,000 --> 00:02:09,000
迈出这一步就相当于

36
00:02:09,000 --> 00:02:12,568
按照以下方式更新权重和偏差

37
00:02:12,568 --> 00:02:17,375
权重 Wi 现在将变成 Wi’

38
00:02:17,375 --> 00:02:23,864
等于 Wi 减去 α 乘以误差对于 Wi 的偏导数

39
00:02:23,864 --> 00:02:28,979
偏差将变成 b’

40
00:02:28,979 --> 00:02:34,164
它等于 b 减去 α 乘以误差对于 b 的偏导数

41
00:02:34,163 --> 00:02:36,168
这样我们得到了一个误差较低的预测

42
00:02:36,169 --> 00:02:40,039
所以可以得出结论：

43
00:02:40,038 --> 00:02:43,698
现在权重为 w’ 和 b’ 的预测

44
00:02:43,699 --> 00:02:48,085
比之前权重为 W 和 b 的预测更好

45
00:02:48,085 --> 00:02:51,000
以上就是关于梯度下降法的内容

