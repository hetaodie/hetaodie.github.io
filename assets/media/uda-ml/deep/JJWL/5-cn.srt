1
00:00:00,000 --> 00:00:02,370
在上个视频结束时

2
00:00:02,370 --> 00:00:06,298
我们处理了数据并指定了模型

3
00:00:06,299 --> 00:00:09,539
目前所有约 600,000 个权重

4
00:00:09,538 --> 00:00:13,719
都具有随机值 因此模型是随机预测结果

5
00:00:13,720 --> 00:00:15,118
通过训练模型

6
00:00:15,118 --> 00:00:18,605
我们将修改这些权重并改善预测结果

7
00:00:18,605 --> 00:00:20,535
但是在训练模型之前

8
00:00:20,535 --> 00:00:24,179
我们需要指定损失函数

9
00:00:24,178 --> 00:00:27,853
因为我们构建的是多类别分类器

10
00:00:27,855 --> 00:00:32,380
因此将使用分类交叉熵损失

11
00:00:32,380 --> 00:00:36,149
该损失函数通过将模型的预测结果与实际标签进行对比

12
00:00:36,149 --> 00:00:41,603
看看我们的模型是否能够很好地分类图片

13
00:00:41,603 --> 00:00:43,649
注意 真正的标签是一位one-hot 编码

14
00:00:43,649 --> 00:00:47,975
每个标签是具有 10 个项目的向量

15
00:00:47,975 --> 00:00:51,000
模型输出向量也是 10 个项目

16
00:00:51,000 --> 00:00:54,795
假设模型返回这个预测结果

17
00:00:54,795 --> 00:00:57,689
它预测图片中的数字是 8 的概率是 90%

18
00:00:57,689 --> 00:01:03,975
是 3 的概率是 10%

19
00:01:03,975 --> 00:01:08,530
实际上 你还可以将标签向量看做概率

20
00:01:08,530 --> 00:01:15,129
它知道图片有 100% 的概率描绘的是 3

21
00:01:15,129 --> 00:01:19,813
分类交叉熵损失查看这两个向量

22
00:01:19,813 --> 00:01:25,689
如果这两个向量对图片中的数字保持相同的意见 那么返回一个较低的值

23
00:01:25,688 --> 00:01:29,573
这里 模型非常确定数字是 8

24
00:01:29,572 --> 00:01:33,464
但是标签很确定数字是 3

25
00:01:33,465 --> 00:01:37,245
因此损失函数将返回一个更高的值

26
00:01:37,245 --> 00:01:40,459
如果模型稍后返回这个输出

27
00:01:40,459 --> 00:01:45,909
并改为 90% 确定图片中的数字是 3

28
00:01:45,909 --> 00:01:50,536
那么分类交叉熵损失将更低

29
00:01:50,537 --> 00:01:55,974
总结下 我们看到如果模型预测结果与标签的一致

30
00:01:55,974 --> 00:01:57,880
那么损失很低

31
00:01:57,879 --> 00:02:00,198
我们对好的模型也是这种期望

32
00:02:00,200 --> 00:02:03,155
我们希望预测结果与标签的一致

33
00:02:03,155 --> 00:02:06,405
我们将尝试寻找使预测结果 

34
00:02:06,405 --> 00:02:09,519
能够最小化损失函数的模型参数

35
00:02:09,519 --> 00:02:11,974
在上节课

36
00:02:11,973 --> 00:02:13,657
我们让大家将损失函数

37
00:02:13,657 --> 00:02:17,708
想象成代表山峦的表面

38
00:02:17,710 --> 00:02:20,675
要最小化该函数

39
00:02:20,675 --> 00:02:25,724
我们只需找到降落到最低山谷的道路

40
00:02:25,723 --> 00:02:30,838
降低损失函数的标准方法是梯度下降

41
00:02:30,840 --> 00:02:33,628
我们介绍了几种实现梯度下降的方法

42
00:02:33,627 --> 00:02:39,578
在 Keras 中每种方法都对应一个优化程序

43
00:02:39,580 --> 00:02:43,344
这里描绘的表面是一种损失函数示例

44
00:02:43,342 --> 00:02:48,817
所有优化程序都希望获得函数最小值

45
00:02:48,818 --> 00:02:52,168
可以看出 有些优化程序的效果比其他的更好

46
00:02:52,169 --> 00:02:56,539
建议你在代码中实验所有这些优化程序

47
00:02:56,538 --> 00:03:02,513
在这节课 示例将始终使用 RMSProp 作为优化程序

48
00:03:02,514 --> 00:03:04,064
当我们编译该函数时

49
00:03:04,062 --> 00:03:07,804
我们将指定损失函数和优化程序

50
00:03:07,805 --> 00:03:11,715
通过将这个额外参数添加为准确率指标

51
00:03:11,715 --> 00:03:18,039
我们将能够检查我们的模型准确率在训练流程中是如何变化的

52
00:03:18,038 --> 00:03:19,618
编译模型后

53
00:03:19,620 --> 00:03:22,395
我们可以先查看对于测试集

54
00:03:22,395 --> 00:03:26,375
它已经具备的准确率 然后再去训练它

55
00:03:26,375 --> 00:03:29,639
我们并不期望它比随机情况效果更好

56
00:03:29,639 --> 00:03:35,400
这里对应的是 10% 的准确率

57
00:03:35,400 --> 00:03:39,425
耶！我们达到了 13% 的准确率

58
00:03:39,425 --> 00:03:43,000
我们将在下节课对其进行训练 使其效果好很多

