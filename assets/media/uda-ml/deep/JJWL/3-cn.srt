1
00:00:00,000 --> 00:00:03,720
我们先来研究下深度学习可以如何用来

2
00:00:03,720 --> 00:00:07,448
识别手写的数字

3
00:00:07,448 --> 00:00:11,939
我们将设计一个图片分类算法

4
00:00:11,939 --> 00:00:17,393
该算法会对手写数字进行拍照 并识别图片中的数字

5
00:00:17,393 --> 00:00:20,368
为此 我们将使用 MNIST 数据集

6
00:00:20,370 --> 00:00:24,989
其中包含了 70000 个手写数字灰度图片

7
00:00:24,989 --> 00:00:29,065
每幅图片都描述了一个从 0 到 9 的数字

8
00:00:29,065 --> 00:00:30,839
该数据集或许是

9
00:00:30,838 --> 00:00:34,689
机器学习领域最有名的数据集之一

10
00:00:34,689 --> 00:00:38,204
在接下来的几个视频中 我们都将用到该数据集

11
00:00:38,204 --> 00:00:43,725
强烈建议你按照下面链接的 Jupyter notebook 跟着操作

12
00:00:43,725 --> 00:00:47,085
在 Keras 中下载 MNIST 比较简单

13
00:00:47,085 --> 00:00:50,579
导入必要的 python 模块后

14
00:00:50,579 --> 00:00:52,618
只需一行代码就能开始获得

15
00:00:52,618 --> 00:00:57,054
我们的训练和测试图片以及相应的标签

16
00:00:57,054 --> 00:00:59,685
查看了前六幅训练图片之后

17
00:00:59,685 --> 00:01:04,450
很快就会发现某些数字更容易看清

18
00:01:04,450 --> 00:01:07,890
稍微眯下眼 9 就可能看成了 4

19
00:01:07,890 --> 00:01:10,019
可以想象数据集中的某些 3

20
00:01:10,019 --> 00:01:12,900
看起来会像 8

21
00:01:12,900 --> 00:01:16,305
我们的算法需要克服这些难题

22
00:01:16,305 --> 00:01:19,859
为了完成我们的任务 我们需要训练一个算法

23
00:01:19,858 --> 00:01:23,612
该算法能够检查图片并发现规律

24
00:01:23,614 --> 00:01:25,920
它需要从某种程度上了解

25
00:01:25,920 --> 00:01:29,655
手写的 1 怎样才看起来像 1

26
00:01:29,655 --> 00:01:34,515
数字 1 和数字 2 或 3 有何区别

27
00:01:34,515 --> 00:01:37,409
这些规律可以用来

28
00:01:37,409 --> 00:01:41,310
解读尚未见过的图片中的数字

29
00:01:41,310 --> 00:01:47,295
首先我们看看 当我们输入其中一个图片 计算机看到的是什么

30
00:01:47,295 --> 00:01:50,564
计算机会将任何灰度图片解读为一个矩阵

31
00:01:50,563 --> 00:01:54,313
每个图片像素对应一项

32
00:01:54,313 --> 00:02:00,268
MNIST 数据集中的每个图片宽和高均为 28 像素

33
00:02:00,269 --> 00:02:05,709
因此计算机将其看做 28 x 28 的矩阵

34
00:02:05,709 --> 00:02:09,675
白色像素编码为 255

35
00:02:09,675 --> 00:02:12,615
黑色像素编码为 0

36
00:02:12,615 --> 00:02:18,955
灰色像素在矩阵中显示为二者之间的整数

37
00:02:18,955 --> 00:02:20,935
我们将对图片进行快速预处理

38
00:02:20,935 --> 00:02:27,539
调整每个图片 使值位于 0 到 1 之间

39
00:02:27,538 --> 00:02:33,793
为此 我们将每个图片中的每个像素除以 255

40
00:02:33,794 --> 00:02:38,715
在将数据应用到 Keras 中的深度网络之前

41
00:02:38,715 --> 00:02:42,194
我们还需要预处理标签

42
00:02:42,193 --> 00:02:47,628
目前 每个图片拥有一个整数标签

43
00:02:47,627 --> 00:02:51,553
我们需要将其转换为一位one-hot 编码

44
00:02:51,555 --> 00:02:56,634
每个标签将被转换为一个大部分值为 0 的向量

45
00:02:56,633 --> 00:02:59,043
如果原始标签是 7

46
00:02:59,044 --> 00:03:03,020
我们将在向量的第七项里放入 1

47
00:03:03,020 --> 00:03:05,719
我们的第二个训练图片描述的是 3

48
00:03:05,717 --> 00:03:11,877
所以在标签向量的第三项里放入 1 以此类推

49
00:03:11,877 --> 00:03:15,928
我们在 Jupyter 计算机本的第 5 个 cell 里执行此操作

50
00:03:15,930 --> 00:03:19,650
注意 我们的数据似乎已经完全预处理了

51
00:03:19,650 --> 00:03:23,968
你认为我们可以使用上节课的神经网络吗？

52
00:03:23,968 --> 00:03:28,079
我们可以将此图片输入到 MLP 中

53
00:03:28,080 --> 00:03:32,694
然后像之前的分类操作那样进行操作吗？不可以

54
00:03:32,693 --> 00:03:37,024
注意 MLP 仅需要向量输入

55
00:03:37,025 --> 00:03:40,155
因此要向 MLP 输入图片

56
00:03:40,155 --> 00:03:42,943
可以看到已经编码为矩阵

57
00:03:42,943 --> 00:03:46,948
我们首先需要将矩阵转换为向量

58
00:03:46,949 --> 00:03:52,430
我们将用这里描述的小例子来演示这一转换流程

59
00:03:52,430 --> 00:03:58,319
对于 4 x 4 的图片 我们可以构建一个具有 16 个项目的向量

60
00:03:58,318 --> 00:04:04,288
前四个项目对应的是矩阵的第一行

61
00:04:04,288 --> 00:04:09,614
下一批四个项目对应的是第二行 以此类推

62
00:04:09,615 --> 00:04:13,155
对于 28 x 28 的矩阵

63
00:04:13,155 --> 00:04:18,660
将扁平化为具有 784 个项目的向量

64
00:04:18,660 --> 00:04:21,254
将图片编码为向量后

65
00:04:21,254 --> 00:04:25,305
就可以传入 MLP 的输入层了

66
00:04:25,305 --> 00:04:28,000
我们将在下个视频中完成这一步

