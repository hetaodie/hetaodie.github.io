1
00:00:00,000 --> 00:00:06,299
在此视频中 我们将创建一个神经网络 用于发现数据中的规律

2
00:00:06,299 --> 00:00:09,448
训练之后 我们将能够使用该网络

3
00:00:09,448 --> 00:00:13,379
分类新图片中包含的数字

4
00:00:13,380 --> 00:00:17,670
因为我们的数据点是有 784 个项目的向量

5
00:00:17,670 --> 00:00:22,015
因此输入层将有 784 个节点

6
00:00:22,015 --> 00:00:27,660
我们先从两个隐藏节点开始 每个均包含 512 个节点

7
00:00:27,660 --> 00:00:30,524
我们的输出层需要在 10 个不同的数字之间进行区分

8
00:00:30,524 --> 00:00:34,810
因此节点设为 10 个

9
00:00:34,810 --> 00:00:36,914
在这节课 我始终会在最后的全连接层上

10
00:00:36,914 --> 00:00:41,625
添加一个 softmax 激活函数

11
00:00:41,625 --> 00:00:44,490
这样可以确保网络会输出

12
00:00:44,490 --> 00:00:49,109
图片描绘的是每个潜在数字的概率估值

13
00:00:49,109 --> 00:00:53,320
现在我们将在 keras 中指定这个草稿模型

14
00:00:53,320 --> 00:00:57,493
如果你还记得在上节课是如何指定神经网络的

15
00:00:57,493 --> 00:01:00,375
那么这段代码看起来应该很相似

16
00:01:00,375 --> 00:01:02,579
我只增加一行新内容

17
00:01:02,579 --> 00:01:05,019
即展平层

18
00:01:05,019 --> 00:01:09,000
这一层出现在指定 MLP 之前

19
00:01:09,000 --> 00:01:13,390
它获得图片矩阵的输入并将其转换为向量

20
00:01:13,390 --> 00:01:19,855
在模型摘要中可以看到它输出了一个具有 784 个项目的向量

21
00:01:19,855 --> 00:01:23,459
对于首次创建而言 这个模型不错了

22
00:01:23,459 --> 00:01:28,215
但是我们将使用你在上节课学过的工具对其进行优化

23
00:01:28,215 --> 00:01:33,930
我们将向所有隐藏层添加一个 ReLU 激活函数

24
00:01:33,930 --> 00:01:35,939
注意 这个函数不会处理所有正值

25
00:01:35,938 --> 00:01:40,362
并将所有负值处理为 0

26
00:01:40,364 --> 00:01:45,329
我们知道 ReLU 函数可以帮助解决梯度消失问题

27
00:01:45,328 --> 00:01:47,878
通过添加 ReLU 函数

28
00:01:47,879 --> 00:01:52,739
可以使模型的准确率大大提高

29
00:01:52,739 --> 00:01:59,245
该激活函数也广泛应用于卷积神经网络

30
00:01:59,245 --> 00:02:00,915
训练该新模型后

31
00:02:00,915 --> 00:02:04,980
你会发现某些过拟合现象

32
00:02:04,980 --> 00:02:07,829
模型能够很好地预测训练数据集中的数字

33
00:02:07,828 --> 00:02:12,234
但是测试图片的识别效果却不太好

34
00:02:12,235 --> 00:02:15,770
你很快就能自己研究这一点

35
00:02:15,770 --> 00:02:19,004
在此期间 为了尽量避免过拟合现象

36
00:02:19,002 --> 00:02:23,817
我们在上节课学到了 可以添加 dropout 层

37
00:02:23,818 --> 00:02:26,413
我们将向该模型添加几个 dropout 层

38
00:02:26,413 --> 00:02:33,103
注意 必须向 dropout 层提供 0 到 1 之间的参数

39
00:02:33,104 --> 00:02:36,000
该值对应的是网络中的任何节点

40
00:02:36,000 --> 00:02:40,002
在训练期间被忽略的概率

41
00:02:40,002 --> 00:02:41,859
在设定该值时

42
00:02:41,860 --> 00:02:46,258
建议先从小的值开始 看看网络有何响应

43
00:02:46,258 --> 00:02:50,068
然后如果觉得有必要增大的话 再增大这一值

44
00:02:50,068 --> 00:02:54,133
我们选择将该参数设为 0.2

45
00:02:54,133 --> 00:02:58,000
在下个视频中 我们将继续处理该模型

