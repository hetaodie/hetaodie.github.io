1
00:00:00,000 --> 00:00:02,930
现在我们已经定义了什么是神经网络

2
00:00:02,930 --> 00:00:04,620
我们需要知道如何训练它们

3
00:00:04,620 --> 00:00:07,259
训练它们实际上就是各边的权重应该是多少

4
00:00:07,259 --> 00:00:10,710
这样才能很好地对数据建模

5
00:00:10,710 --> 00:00:13,290
为了学习如何训练它们 我们需要仔细研究

6
00:00:13,288 --> 00:00:16,794
它们如何处理输入来获得输出结果

7
00:00:16,795 --> 00:00:20,220
我们看看我们的简单神经网络 一个感知器

8
00:00:20,219 --> 00:00:24,199
这个感知器接收了 (x1,x2) 形式的数据点

9
00:00:24,199 --> 00:00:27,259
标签是 y = 1

10
00:00:27,260 --> 00:00:29,425
意味着这个点是蓝色的

11
00:00:29,425 --> 00:00:31,980
感知器由线性方程定义

12
00:00:31,980 --> 00:00:35,798
例如 w1x1 + w2x2 + b

13
00:00:35,798 --> 00:00:41,579
其中 w1 和 w2 是权重（边） b 是偏差（节点）

14
00:00:41,579 --> 00:00:43,554
这里 w1 大于 w2

15
00:00:43,554 --> 00:00:46,200
我们表示为将用 w1 标记的边

16
00:00:46,200 --> 00:00:49,830
画的比用 w2 标记的边粗很多

17
00:00:49,829 --> 00:00:53,280
感知器画出点 (x1,x2)

18
00:00:53,280 --> 00:00:57,225
并输出点是蓝色的概率

19
00:00:57,225 --> 00:01:01,300
对于这个红色区域的点 输出是个很小的数字

20
00:01:01,298 --> 00:01:04,019
因为这个点不太可能是蓝色

21
00:01:04,019 --> 00:01:07,045
这个流程叫做前向反馈

22
00:01:07,045 --> 00:01:10,745
我们可以看出这个模型不好 因为这个点实际上是蓝色的

23
00:01:10,745 --> 00:01:12,575
依据是第三个坐标

24
00:01:12,575 --> 00:01:14,900
y 是 1

25
00:01:14,900 --> 00:01:18,560
如果我们有更复杂的神经网络 其实流程是一样的

26
00:01:18,560 --> 00:01:20,840
粗边对应的是大的权重

27
00:01:20,840 --> 00:01:24,859
细边对应的是小的权重

28
00:01:24,858 --> 00:01:30,184
神经网络在上下图表中都绘出这个点

29
00:01:30,185 --> 00:01:34,769
得出的结果是顶部模型的小数字

30
00:01:34,769 --> 00:01:38,569
那么这个位于红色区域的点是蓝色的概率很小

31
00:01:38,569 --> 00:01:42,879
从第二个模型得出一个大的数字

32
00:01:42,879 --> 00:01:44,978
点在蓝色区域 意味着

33
00:01:44,980 --> 00:01:47,674
它是蓝色的概率很大

34
00:01:47,674 --> 00:01:50,170
这两个模型结合为

35
00:01:50,170 --> 00:01:53,170
这个非线性模型

36
00:01:53,170 --> 00:01:57,765
输出层绘出这个点 告诉我们是蓝色的概率

37
00:01:57,765 --> 00:02:00,608
可以看出 这个模型不好

38
00:02:00,608 --> 00:02:04,214
因为它将点绘在红色区域 但是点是蓝色

39
00:02:04,215 --> 00:02:08,365
再强调下 这个流程叫做前向反馈 我们将仔细研究这一概念

40
00:02:08,365 --> 00:02:10,715
这是另一种标记法的神经网络

41
00:02:10,715 --> 00:02:13,444
偏差在外面

42
00:02:13,443 --> 00:02:15,233
现在有了权重矩阵

43
00:02:15,235 --> 00:02:18,860
矩阵 W(1) 表示第一层级

44
00:02:18,860 --> 00:02:23,155
条目是从权重 W11 到 W32

45
00:02:23,155 --> 00:02:28,460
注意 现在偏差写成了 W31 和 W32

46
00:02:28,460 --> 00:02:30,520
这只是为了方便

47
00:02:30,520 --> 00:02:32,585
下一层级依然有一个矩阵

48
00:02:32,585 --> 00:02:36,064
W(2) 表示第二层级

49
00:02:36,063 --> 00:02:38,828
这一层级包含的权重告诉我们

50
00:02:38,830 --> 00:02:43,490
如何将第一层级的线性模型组合成第二层级的非线性模型

51
00:02:43,490 --> 00:02:45,019
其中用到了一些数学知识

52
00:02:45,019 --> 00:02:46,480
输入是 x1 x2 的形式

53
00:02:46,479 --> 00:02:50,435
1 是偏置单元

54
00:02:50,435 --> 00:02:55,435
我们将其与矩阵 W(1) 相乘 得出这些输出结果

55
00:02:55,435 --> 00:03:01,259
然后应用 s 型函数 将输出变成 0 到 1 之间的值

56
00:03:01,258 --> 00:03:05,298
这些值形成的向量加上偏置单元 1

57
00:03:05,300 --> 00:03:08,330
与第二个矩阵相乘

58
00:03:08,330 --> 00:03:10,880
对返回的输出应用 s 型函数

59
00:03:10,878 --> 00:03:15,334
获得最终结果 即 ŷ

60
00:03:15,335 --> 00:03:21,170
ŷ 是预测 即点标为蓝色的概率

61
00:03:21,169 --> 00:03:23,299
这就是神经网络的作用

62
00:03:23,300 --> 00:03:25,760
它们传入输入向量

63
00:03:25,758 --> 00:03:29,083
应用线性模型序列和 s 型函数

64
00:03:29,085 --> 00:03:30,439
这些特征图相结合

65
00:03:30,438 --> 00:03:33,198
变成高度非线性特征图

66
00:03:33,199 --> 00:03:37,669
最终公式是

67
00:03:37,669 --> 00:03:43,314
ŷ = σW(2)*σW(1)(x)

68
00:03:43,313 --> 00:03:45,098
再重复一遍

69
00:03:45,098 --> 00:03:48,718
我们在多层级感知器或神经网络上再来一遍

70
00:03:48,718 --> 00:03:51,125
要计算预测 ŷ

71
00:03:51,125 --> 00:03:53,229
我们从单位向量 x 开始

72
00:03:53,229 --> 00:03:55,569
然后应用第一个矩阵和 s 型函数

73
00:03:55,568 --> 00:04:00,328
得出第二层级的值

74
00:04:00,330 --> 00:04:03,070
然后应用第二个矩阵和另一个 s 型函数

75
00:04:03,068 --> 00:04:06,723
得出第三层级的值

76
00:04:06,723 --> 00:04:13,448
以此类推 直到得出最终预测 ŷ

77
00:04:13,449 --> 00:04:16,420
这就是神经网络从输入向量中

78
00:04:16,420 --> 00:04:20,000
获得预测用到的前向反馈流程

