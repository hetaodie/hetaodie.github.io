1
00:00:00,000 --> 00:00:01,215
在这节课的前面阶段

2
00:00:01,215 --> 00:00:03,450
我们介绍了计算策略

3
00:00:03,450 --> 00:00:07,425
对应的值函数的迭代方法

4
00:00:07,424 --> 00:00:10,394
在本视频中 我们将详细讲解该算法

5
00:00:10,394 --> 00:00:13,605
该算法称为迭代策略评估

6
00:00:13,605 --> 00:00:15,960
假设智能体已经完全了解

7
00:00:15,960 --> 00:00:20,940
关于环境的 MDP

8
00:00:20,940 --> 00:00:23,220
注意 该算法的依据是

9
00:00:23,219 --> 00:00:26,914
状态值函数的贝尔曼预期方程

10
00:00:26,914 --> 00:00:29,875
该方程本质上是个方程组

11
00:00:29,875 --> 00:00:33,164
因为每个环境状态都有一个方程

12
00:00:33,164 --> 00:00:38,994
每个方程将状态值与后续状态的值关联起来

13
00:00:38,994 --> 00:00:41,625
理论上来说 如果有一个方程组

14
00:00:41,625 --> 00:00:44,234
每个未知元素都有一个方程

15
00:00:44,234 --> 00:00:46,354
那么可以求解该方程组

16
00:00:46,354 --> 00:00:49,959
但是还有一种更简单的方法 我们不用完全求解该方程组

17
00:00:49,960 --> 00:00:53,340
而是构建一个迭代算法

18
00:00:53,340 --> 00:00:57,435
每一步都使我们越来越接近于求解该方程组

19
00:00:57,435 --> 00:01:02,355
具体而言 我们的迭代算法将调整该贝尔曼方程

20
00:01:02,354 --> 00:01:04,579
因此可以当做更新规则

21
00:01:04,579 --> 00:01:09,420
大写的 V 表示对策略的值函数的当前猜测

22
00:01:09,420 --> 00:01:11,460
注意 我只更改了贝尔曼方程的两个部分

23
00:01:11,459 --> 00:01:15,149
我用黄色标出来了

24
00:01:15,150 --> 00:01:21,109
该算法先对策略的值函数进行初始猜测

25
00:01:21,109 --> 00:01:25,150
通常是将每个状态的初始猜测设为 0

26
00:01:25,150 --> 00:01:27,990
因此不可能这就是真正的值函数

27
00:01:27,989 --> 00:01:31,884
但是我们只是进行一个初始猜测

28
00:01:31,885 --> 00:01:34,200
然后我们将循环访问每个状态

29
00:01:34,200 --> 00:01:37,844
并使用更新规则改善对状态值函数的猜测

30
00:01:37,844 --> 00:01:42,164
真正妙的是只要满足几个技术性条件

31
00:01:42,165 --> 00:01:47,600
这个算法就能保证会向该策略的值函数收敛

32
00:01:47,599 --> 00:01:50,159
要获得真正的收敛效果

33
00:01:50,159 --> 00:01:52,909
就必须运行该算法无限次

34
00:01:52,909 --> 00:01:55,200
这在现实中是不可行的

35
00:01:55,200 --> 00:01:58,719
因此我们将在刚要真正收敛之前停止

36
00:01:58,719 --> 00:02:03,655
问题是 如何判断已经很接近了？

37
00:02:03,655 --> 00:02:06,150
在现实中 当你实现该算法时

38
00:02:06,150 --> 00:02:09,289
你将发现前几次应用更新规则时

39
00:02:09,289 --> 00:02:12,044
值函数的变化非常大

40
00:02:12,044 --> 00:02:14,864
但是在后续阶段

41
00:02:14,865 --> 00:02:17,905
你将发现几乎没有变化

42
00:02:17,905 --> 00:02:20,400
当我们应用更新规则后

43
00:02:20,400 --> 00:02:24,200
值函数的估值变化不大

44
00:02:24,199 --> 00:02:26,939
这种情况就强烈表示

45
00:02:26,939 --> 00:02:30,104
我们的算法已经非常收敛于真正的值函数

46
00:02:30,104 --> 00:02:32,234
因此

47
00:02:32,235 --> 00:02:34,980
我们可以设计一个停止条件

48
00:02:34,979 --> 00:02:38,759
当我们完整地遍历了所有状态

49
00:02:38,759 --> 00:02:41,459
所有值都没有什么变化时 则停止该算法

50
00:02:41,460 --> 00:02:45,390
为此 我们将修改伪代码

51
00:02:45,389 --> 00:02:49,944
第一步是需要你来设置一个非常小的正 θ

52
00:02:49,944 --> 00:02:55,989
然后和之前一样 将值函数的初始猜测全设为 0

53
00:02:55,990 --> 00:02:59,460
然后进行迭代循环

54
00:02:59,460 --> 00:03:01,560
在每一步应用贝尔曼更新规则

55
00:03:01,560 --> 00:03:04,949
检查每个状态的值变化幅度

56
00:03:04,949 --> 00:03:07,259
如果所有状态的最大变化

57
00:03:07,259 --> 00:03:10,169
小于所设置的小数字 θ

58
00:03:10,169 --> 00:03:12,239
则停止该算法

59
00:03:12,240 --> 00:03:15,254
并表示值函数的估值已经很不错

60
00:03:15,254 --> 00:03:20,805
就这样 如果你不太熟悉这个更新步骤 也不用担心

61
00:03:20,805 --> 00:03:23,469
你的直觉是想证明这一步 这很正常

62
00:03:23,469 --> 00:03:27,740
这个算法并不是那么的直观

63
00:03:27,740 --> 00:03:31,950
下面说说更新步骤的原理

64
00:03:31,949 --> 00:03:37,079
我们循环访问状态 并且每次向一个状态应用更新规则

65
00:03:37,080 --> 00:03:39,195
然后对于每个状态

66
00:03:39,194 --> 00:03:41,849
智能体都可以选择任何一个潜在的动作

67
00:03:41,849 --> 00:03:47,284
并进入任何一个潜在后续状态

68
00:03:47,284 --> 00:03:50,460
贝尔曼方程可以帮助我们将此父状态的值

69
00:03:50,460 --> 00:03:55,615
与所有潜在后续状态的值相关联

70
00:03:55,615 --> 00:03:59,835
现在我们查看父状态的估算值函数

71
00:03:59,835 --> 00:04:03,305
以及后续状态的值

72
00:04:03,305 --> 00:04:06,050
如果将这些值代入贝尔曼方程

73
00:04:06,050 --> 00:04:07,840
会发现方程不满足

74
00:04:07,840 --> 00:04:10,590
我们将更改父状态的值

75
00:04:10,590 --> 00:04:14,550
以便满足贝尔曼方程

76
00:04:14,550 --> 00:04:17,685
然后对第二个状态执行相同的流程 以此类推

77
00:04:17,685 --> 00:04:20,610
需要注意的是

78
00:04:20,610 --> 00:04:23,790
如果在某个时刻应用该更新规则时

79
00:04:23,790 --> 00:04:27,500
任何状态的任何值都没有变化

80
00:04:27,500 --> 00:04:31,350
则表明 我们获得了完全满足贝尔曼方程的值函数

81
00:04:31,350 --> 00:04:36,715
唯一满足这一条件的值函数是真正的策略值函数

82
00:04:36,714 --> 00:04:39,994
在本视频中我们将不再赘述

83
00:04:39,995 --> 00:04:41,490
但是和往常一样 如果你想深入了解

84
00:04:41,490 --> 00:04:46,220
建议你在问答时间内提出问题或将问题发布到相关 slack 频道上

85
00:04:46,220 --> 00:04:50,000
现在该你自己来实现该算法了

