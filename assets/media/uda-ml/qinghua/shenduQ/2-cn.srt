1
00:00:00,000 --> 00:00:03,950
如何在强化学习中使用神经网络

2
00:00:03,950 --> 00:00:10,515
还记得我们将神经网络介绍为通用函数逼近器这部分内容吗？

3
00:00:10,515 --> 00:00:14,730
如果我们使用神经网络表示值函数呢？

4
00:00:14,730 --> 00:00:18,120
可行吗？我们来仔细研究下

5
00:00:18,120 --> 00:00:22,320
状态值函数将任何状态 s 映射到实数

6
00:00:22,320 --> 00:00:27,554
表示根据当前策略 π 该状态的重要性

7
00:00:27,554 --> 00:00:31,064
如果我们使用神经网络估算该函数

8
00:00:31,065 --> 00:00:34,789
则输入需要以向量的形式提供进来

9
00:00:34,789 --> 00:00:39,359
现在我们已经知道如何使用特征转换 x 执行这一步

10
00:00:39,359 --> 00:00:42,960
现在输入可以经过神经网络

11
00:00:42,960 --> 00:00:46,454
如果它旨在输出一个实数

12
00:00:46,454 --> 00:00:47,774
即网络

13
00:00:47,774 --> 00:00:49,909
估算的值

14
00:00:49,909 --> 00:00:52,439
很棒！这与利用形成参数向量 W 的

15
00:00:52,439 --> 00:00:56,250
神经网络权重估算值函数

16
00:00:56,250 --> 00:00:59,219
这一基本概念相符

17
00:00:59,219 --> 00:01:04,450
问题是如何学习这些参数

18
00:01:04,450 --> 00:01:08,170
如果我们有一个参考或想要实现的目标

19
00:01:08,170 --> 00:01:11,500
例如某个预言者提供的 vπ 我们可以将估算值和目标值

20
00:01:11,500 --> 00:01:17,579
之间的平方差当做误差或损失

21
00:01:17,579 --> 00:01:20,230
然后我们可以沿着神经网络

22
00:01:20,230 --> 00:01:23,760
反向传播并调整权重 以便最小化损失

23
00:01:23,760 --> 00:01:27,445
调整权重的一个热门方法是梯度下降

24
00:01:27,444 --> 00:01:32,500
我们朝着误差的反方向以迭代方式小步地更改权重

25
00:01:32,500 --> 00:01:34,927
为了应用梯度下降

26
00:01:34,927 --> 00:01:37,644
我们需要知道网络表示的

27
00:01:37,644 --> 00:01:42,129
相对于权重的值函数

28
00:01:42,129 --> 00:01:44,739
这一步可能会非常复杂

29
00:01:44,739 --> 00:01:47,875
尤其是具有深度架构的网络

30
00:01:47,875 --> 00:01:52,674
但是我们在 TensorFlow Theano 和 MXNet 等库中

31
00:01:52,674 --> 00:01:56,530
实现了非常高效的算法 可以帮助我们训练神经网络

32
00:01:56,530 --> 00:01:58,704
我们只需用于计算损失的方法

33
00:01:58,704 --> 00:02:02,799
这时候强化学习知识就派上用场了

34
00:02:02,799 --> 00:02:08,254
此刻 我们再考虑下动作值函数 Q

35
00:02:08,254 --> 00:02:11,949
更新规则看起来和状态值函数 V 的非常相似

36
00:02:11,949 --> 00:02:16,299
但是这里具有相同的问题

37
00:02:16,300 --> 00:02:18,451
对于大多数实际问题

38
00:02:18,450 --> 00:02:24,014
没有预言家能告诉我们正确的值函数 vπ 或 qπ 应该是多少

39
00:02:24,014 --> 00:02:26,799
我们需要使用更加现实的目标

40
00:02:26,800 --> 00:02:30,750
这个目标基于我们与环境的互动

41
00:02:30,750 --> 00:02:36,310
这正是强化学习与监督学习的根本区别

42
00:02:36,310 --> 00:02:39,580
接下来我们将了解如何查找合适的目标

43
00:02:39,580 --> 00:02:45,000
以便替换这些方程中的真正值函数所采用的策略

