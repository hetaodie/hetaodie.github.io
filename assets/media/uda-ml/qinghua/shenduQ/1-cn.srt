1
00:00:02,910 --> 00:00:07,480
深度 Q 学习是一种演示

2
00:00:07,480 --> 00:00:11,470
如何使用神经网络解决强化学习问题的精彩算法

3
00:00:11,470 --> 00:00:14,506
它扩展了我们可以解决的领域范围

4
00:00:14,506 --> 00:00:18,175
尤其是具有很大连续状态空间的领域

5
00:00:18,175 --> 00:00:21,565
我相信你肯定迫不及待地想要知道它的原理了

6
00:00:21,565 --> 00:00:24,370
这正是我们在这节课中将讨论的内容

7
00:00:24,370 --> 00:00:29,950
首先我们将看看可以如何使用神经网络表示值函数

8
00:00:29,949 --> 00:00:34,225
接着 我们将调整两大主要免模型方法

9
00:00:34,225 --> 00:00:39,320
即蒙特卡洛和时间差分学习 以便采用这种新的表示法

10
00:00:39,320 --> 00:00:43,274
Q 学习是 TD 学习的一个变体

11
00:00:43,274 --> 00:00:45,299
因此这节课将使你了解

12
00:00:45,299 --> 00:00:48,314
和自己实现深度 Q 学习算法

13
00:00:48,314 --> 00:00:51,299
最后 你将学习如何利用深度学习

14
00:00:51,299 --> 00:00:54,659
包括卷积神经网络和递归神经网络

15
00:00:54,659 --> 00:00:57,959
指导计算机完成几乎不可能从头学习的任务

16
00:00:57,960 --> 00:01:01,950
例如玩视频游戏

