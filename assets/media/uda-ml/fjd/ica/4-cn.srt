1
00:00:00,000 --> 00:00:02,040
欢迎回来 在本节视频课程

2
00:00:02,040 --> 00:00:06,389
我们将继续介绍独立成分分析算法

3
00:00:06,389 --> 00:00:08,105
这轮讲解的内容比较笼统

4
00:00:08,105 --> 00:00:10,365
我们不会深入研究数学层面的问题

5
00:00:10,365 --> 00:00:15,780
而是会引导你朝正确的方向学习  

6
00:00:15,779 --> 00:00:18,539
了解该算法大致的运作原理

7
00:00:18,539 --> 00:00:22,434
以及使用时所需的假设 就很好很有价值了

8
00:00:22,434 --> 00:00:25,327
那么 我们现在有什么呢？

9
00:00:25,327 --> 00:00:28,829
我们有一个名为 X 的数据集

10
00:00:28,829 --> 00:00:37,379
该数据集是通过乘以混合矩阵生成的

11
00:00:37,380 --> 00:00:40,170
混合矩阵也就是信源信号 A

12
00:00:40,170 --> 00:00:41,460
我们也没有

13
00:00:41,460 --> 00:00:43,950
所以 我们没有 A 也没有 S

14
00:00:43,950 --> 00:00:46,760
S 是我们最终想要计算得出的结果

15
00:00:46,759 --> 00:00:55,089
所以 如果 X=A×S 我们可以说 S 为 信源

16
00:00:55,090 --> 00:00:58,710
这里你想求得的是 W

17
00:00:58,710 --> 00:01:01,725
也就是 A 的倒数

18
00:01:01,725 --> 00:01:05,480
那么 如果 A 为混合矩阵 我们就可以称 W 为非混合矩阵

19
00:01:05,480 --> 00:01:09,530
W 为非混合矩阵× X 即乘以我们所有的某数据集

20
00:01:09,530 --> 00:01:12,605
也就是我们的原录音

21
00:01:12,605 --> 00:01:15,105
那么在该公式中

22
00:01:15,105 --> 00:01:16,780
X 是我们所有的输入项

23
00:01:16,780 --> 00:01:19,849
需要计算得出 W

24
00:01:19,849 --> 00:01:21,704
S 为结果

25
00:01:21,704 --> 00:01:27,784
所以 独立成分分析算法和其过程全部的目标是趋近 W 

26
00:01:27,784 --> 00:01:37,569
或者给出最佳的 W 以与 X 即该数据集相乘 来产生原始信号

27
00:01:39,159 --> 00:01:45,670
名为《独立成分分析：算法与应用》的论文

28
00:01:45,670 --> 00:01:50,945
对独立成分分析算法作出了清楚的解释 

29
00:01:50,944 --> 00:01:53,664
它衍生出了这里的所有事物

30
00:01:53,665 --> 00:02:01,445
也展示了该算法各部分的多种计算方法

31
00:02:01,444 --> 00:02:05,769
但是如果我们只想宏观地学习一下这种算法

32
00:02:05,769 --> 00:02:09,185
就可以使用固定点算法 这只是一种方法

33
00:02:09,185 --> 00:02:14,332
实际上也应用在 scikit-learn 中

34
00:02:14,332 --> 00:02:16,090
首先 我们有 X

35
00:02:16,090 --> 00:02:17,366
这是我们的数据集

36
00:02:17,366 --> 00:02:20,135
我们将其居中 白化

37
00:02:20,134 --> 00:02:23,751
然后 选择一个初始的随机权重矩阵

38
00:02:23,752 --> 00:02:27,760
我们称之为 W 第三步

39
00:02:27,759 --> 00:02:32,394
我们对 W 做出预估 W 是包括多个向量的矩阵

40
00:02:32,395 --> 00:02:36,605
每个向量都是权值向量

41
00:02:36,604 --> 00:02:41,424
预估后 我们进行去相关操作

42
00:02:41,425 --> 00:02:46,885
即防止 W1 和 W2 转化为同样的值

43
00:02:46,884 --> 00:02:51,795
我们希望它们转化为不同的量

44
00:02:51,795 --> 00:02:56,655
然后 我们重复第三步 直到发生转换

45
00:02:56,655 --> 00:03:02,134
直到我们找到我们满意的 W 值

46
00:03:02,134 --> 00:03:06,044
所以 大部分数学运算都发生在第三步

47
00:03:06,044 --> 00:03:10,364
那么估算是如何进行的呢？

48
00:03:10,365 --> 00:03:15,670
这是用于估算每个向量的公式

49
00:03:15,669 --> 00:03:19,584
E 是期望值

50
00:03:19,585 --> 00:03:21,865
x 是数据集

51
00:03:21,865 --> 00:03:25,360
g 为非二次函数

52
00:03:25,360 --> 00:03:29,470
我们可以在常用公式

53
00:03:29,469 --> 00:03:31,650
和 scikit-learn 所用公式中

54
00:03:31,650 --> 00:03:37,715
选择多个公式 或是论文中提出的一个可选项 双曲正切

55
00:03:37,715 --> 00:03:42,414
正切函数

56
00:03:42,414 --> 00:03:47,504
去相关操作像这样计算

57
00:03:47,504 --> 00:03:51,069
我们稍微谈一下

58
00:03:51,069 --> 00:03:53,034
因为它看起来有些神秘

59
00:03:53,034 --> 00:03:56,305
独立成分分析会提出若干假设

60
00:03:56,305 --> 00:04:00,849
它假设各成分是分别统计的

61
00:04:00,849 --> 00:04:06,574
该论文对分别统计在统计学语言中的含义稍做解释

62
00:04:06,574 --> 00:04:11,669
它也假设成分须为非高斯分布

63
00:04:11,669 --> 00:04:14,952
非高斯分布在这里很重要

64
00:04:14,953 --> 00:04:20,605
它是估算独立成分分析的关键 没有它就无法计算

65
00:04:20,605 --> 00:04:26,415
如果它们是高斯分布 我们就不能恢复原始信号

66
00:04:26,415 --> 00:04:28,600
有基于此

67
00:04:28,600 --> 00:04:33,070
中心极限定理告诉我们

68
00:04:33,069 --> 00:04:38,814
一些自变量的分布趋向高斯分布

69
00:04:38,814 --> 00:04:43,074
了解了这些 我们取 W

70
00:04:43,074 --> 00:04:45,639
这个权重矩阵

71
00:04:45,639 --> 00:04:52,814
将其作为 W 转置 X 时 实现非高斯分布最大化的矩阵

72
00:04:52,814 --> 00:04:58,279
这样一来 非高斯性又将产生重要影响

73
00:04:58,279 --> 00:05:03,189
但是在这里 我们必须计算非高斯性

74
00:05:03,189 --> 00:05:09,214
因为这是整个算法尝试将其最大化的项目

75
00:05:09,214 --> 00:05:14,149
那如何计算非高斯性呢？

76
00:05:14,149 --> 00:05:19,389
在这个案例中 该术语就相当于所谓的负熵

77
00:05:19,389 --> 00:05:25,314
负熵是信息理论的概念 该理论提出了信息熵的理念

78
00:05:25,314 --> 00:05:30,964
这是大致估计的一种方法

79
00:05:30,964 --> 00:05:33,669
你不必了解所有的细节 只要了解

80
00:05:33,670 --> 00:05:37,249
非高斯性假设

81
00:05:37,249 --> 00:05:42,520
独立成分必须是独立的即可

82
00:05:42,519 --> 00:05:47,620
否则我们不可能发现它们

83
00:05:47,620 --> 00:05:51,759
了解这些条件 

84
00:05:51,759 --> 00:05:56,719
以及独立成分分析运行的情境 是最重要的

85
00:05:56,720 --> 00:06:01,800
如果你想了解细节及其衍生理论

86
00:06:01,800 --> 00:06:03,160
可参阅链接中的论文

