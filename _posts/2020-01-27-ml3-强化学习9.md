---



layout: post
title: 机器学习-强化学习-连续空间中的强化学习
description: 在这章，主要讲解了监督学习相关的技术。
Keywords: 机器学习、模型、评估指标
tagline: 
categories: [ML]
tags: [ML]

---



* 目录
 {:toc  }
# 


## 1、深度强化学习

<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/1-t.mp4"></video>
<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   class="vjs-tech" id="vjs_video_180081_html5_api" tabindex="-1" crossorigin="anonymous" src="https://s3.cn-north-1.amazonaws.com.cn/u-vid-hd/GPjK124RU5g.mp4" style="box-sizing: inherit; margin: 0px; padding: 0px; border: 0px; font: inherit; vertical-align: baseline; width: 754px; height: 424.125px; position: absolute; top: 0px; left: 0px;"><div pseudo="-webkit-media-controls" class="sizing-small phase-ready state-stopped"><br class="Apple-interchange-newline"><div pseudo="-webkit-media-controls-enclosure"></div></div></video>
Play Video



**注意**：\mathcal{R}R 是所有奖励的集合。奖励概率以联合方式与转换概率一起指定为：p(s'', r | s, a) = \mathbb{P}(S_{t+1}=s'', R_{t+1}=r|S_t=s, A_t=a)*p*(*s*′′,*r*∣*s*,*a*)=P(*S**t*+1=*s*′′,*R**t*+1=*r*∣*S**t*=*s*,*A**t*=*a*)



## 2、 资源



如今，深度强化学习是一个非常活跃的研究领域。但是要理解最近出现的先进概念和算法，你需要充分理解强化学习基础知识。



![img](../assets/media/uda-ml/qinghua/lianxukongjianzhongde/2-i1.png)‘如果你以前对强化学习没有经验，或者想复习这方面的知识，请先学习我们自选课程中的强化学习（可选）单元。'



## 编程：OpenAI Gym

在整个课程中，我们将使用 **OpenAI Gym** 作为编程练习。它是一个开发和分享强化学习算法的开源库和平台。如果你之前没有使用过该平台，建议你现在就熟悉一下该平台。

阅读 [OpenAI Gym 文档](https://gym.openai.com/docs/)中的说明，以了解基本语法。

> *该文档提供了在计算机上安装 OpenAI Gym 的说明。你也可以跳过这一步，因为你可以在课堂上完成所有的编程实现。但是我个人建议你安装该工具，因为研究该工具会很有趣！*

还建议你花时间查看 [leaderboard](https://github.com/openai/gym/wiki/Leaderboard)，其中包含了每个任务的最佳解决方案。

请参阅此[博客](https://blog.openai.com/openai-gym-beta/)以详细了解如何使用 OpenAI Gym 加快强化学习 (RL) 研究。

## 教科书：Sutton & Barto，第二版。

建议你阅读这本[经典强化学习教科书](http://go.udacity.com/rl-textbook)中的章节。我们在深度强化学习课程中介绍的知识可以在这本书的***第 II 部分：逼近解决方案***中找到。此外，我们将引用详细介绍特定算法和技巧的重要论文。

> *注意，所有建议的课外阅读延伸都是可选阅读延伸！但是强烈建议你阅读这些资料，尤其当你发现感兴趣的知识点并且想要了解更多信息时，或者对某个知识点不清楚，需要参考其他资料时。*

请参阅此 [GitHub 代码库](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction) 以查看教科书中的大部分图表的 Python 实现。





## 3、离散空间与连续空间

<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/2-t.mp4"></video>
离散空间与连续空间

离散状态空间：s \in \{s_0, s_1, ..., s_n \}*s*∈{*s*0,*s*1,...,*s**n*}

连续状态空间：s \in \mathbb{R}^n*s*∈R*n*

同样，离散动作空间：a \in \{a_0, a_1, ..., a_m \}*a*∈{*a*0,*a*1,...,*a**m*}

以及连续动作空间：a \in \mathbb{R}^m*a*∈R*m*



## 4、空间表示法

<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/3-t.mp4"></video>
![img](../assets/media/uda-ml/qinghua/lianxukongjianzhongde/5-i1.png)



### 练习题

以下哪些状态或动作可以用**离散**表示法表示？

- 玩扑克牌时，手中的牌
- 用机械臂握紧物体时应用的力
- 无人驾驶 GPS 坐标
- 9x9 围棋游戏的棋盘位置
- 键盘乐器上的按键



## 5、离散化

<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/4-t.mp4"></video>

## 6、Tile Coding

<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/5-t.mp4"></video>

## 7、Coarse Coding

<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/6-t.mp4"></video>

## 8、函数逼近

<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/7-t.mp4"></video>

## 9、线性函数逼近

<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/8-t.mp4"></video>

## 10、内核函数

<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/9-t.mp4"></video>

## 11、非线性函数逼近

## 12、总结
<video controls="" preload="none" style="width:100%; height:100%; object-fit: fill"   src="../assets/media/uda-ml/qinghua/lianxukongjianzhongde/10-t.mp4"></video>