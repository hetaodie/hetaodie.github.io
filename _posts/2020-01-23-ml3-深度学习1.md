---




layout: post
title: 机器学习-深度学习-神经网络
description: 在这章，主要讲解了监督学习相关的技术。
Keywords: 机器学习、模型、评估指标
tagline: 
categories: [ML]
tags: [ML]

---



* 目录
 {:toc  }
# 

<!--## 1、欢迎

你好！ 欢迎来到神经网络部分！ 本节将基于你先前在感知算法部分中开始的示例部分进行拓展。因此，你可能会看到一些你以前看过的视频。 如果你需要回顾，可以再学习一遍。如果你不需要回顾，可以直接跳过它们，继续学习新内容。

## 2、简介

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/1-t.mp4"></video>

## 3、分类问题

神经网络是机器学习中的一个模型，可以用于两类问题的解答：

分类：把数据划分成不同的类别
回归：建立数据间的连续关系
首先，来解决神经网络的分类问题
我们开始吧！我们首先将解释什么是分类问题，并用一个简单的例子进行讲解。


<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/2-t.mp4"></video>


## 4、分类问题2

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/3-t.mp4"></video>


## 5、线性界面

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/4-t.mp4"></video>

## 6、更高维度的界线

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/5-t.mp4"></video>
修正：视频中表格下方的箭头囊括范围应不包含最后一列。

## 7、感知器

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/6-t.mp4"></video>
备注：视频 03:24 处的函数应改为 y = 0 if x < 0。

## 8、用感知器实现简单逻辑运算

在这节课，我们要用感知器实现简单的逻辑运算。你将会为最常见的逻辑运算符创建感知器：AND（与）、OR（或） 和 NOT （非）。然后，我们将看看如何处理比较难的 XOR（异或）运算符。我们开始吧！

用感知器实现逻辑运算 - AND （“与”）

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/7-t.mp4"></video>

AND 感知器的权重和偏差是什么？
将权重（weight1、weight2）和偏差 bias 设为正确的值，以便如上所示地计算 AND 运算。



```python
import pandas as pd

# TODO: Set weight1, weight2, and bias
weight1 = 0.0
weight2 = 0.0
bias = 0.0


# DON'T CHANGE ANYTHING BELOW
# Inputs and outputs
test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]
correct_outputs = [False, False, False, True]
outputs = []

# Generate and check output
for test_input, correct_output in zip(test_inputs, correct_outputs):
    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias
    output = int(linear_combination >= 0)
    is_correct_string = 'Yes' if output == correct_output else 'No'
    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])

# Print output
num_wrong = len([output[4] for output in outputs if output[4] == 'No'])
output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])
if not num_wrong:
    print('Nice!  You got it all correct.\n')
else:
    print('You got {} wrong.  Keep trying!\n'.format(num_wrong))
print(output_frame.to_string(index=False))

```

**用感知器实现逻辑运算 - OR （“或”）**



![img](/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/8-i0.png)



OR 感知器和 AND 感知器很相似。在下图中，OR 感知器和 AND 感知器的直线一样，只是直线往下移动了。你可以如何处理权重和/或偏差以实现这一效果？请使用下面的 AND 感知器来创建一个 OR 感知器。



![img](/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/8-i1.png)

**习题 2/4**

从 AND 感知器变成 OR 感知器的两种方法是什么？

- 增大权重
- 减小权重
- 增大单个权重
- 减小单个权重
- 增大偏差大小
- 减小偏差大小

**用感知器实现逻辑运算 - NOT （"非”）**

和我们刚刚研究的其他感知器不一样，NOT 运算仅关心一个输入。如果输入是 `1`，则运算返回 `0`，如果输入是 `0`，则返回 `1`。感知器的其他输入被忽略了。

在此测验中，你将设置权重（`weight1`、`weight2`）和偏差 `bias`，以便对第二个输入进行 NOT 运算，并忽略第一个输入。



```python
import pandas as pd

# TODO: Set weight1, weight2, and bias
weight1 = 0.0
weight2 = 0.0
bias = 0.0


# DON'T CHANGE ANYTHING BELOW
# Inputs and outputs
test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]
correct_outputs = [True, False, True, False]
outputs = []

# Generate and check output
for test_input, correct_output in zip(test_inputs, correct_outputs):
    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias
    output = int(linear_combination >= 0)
    is_correct_string = 'Yes' if output == correct_output else 'No'
    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])

# Print output
num_wrong = len([output[4] for output in outputs if output[4] == 'No'])
output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])
if not num_wrong:
    print('Nice!  You got it all correct.\n')
else:
    print('You got {} wrong.  Keep trying!\n'.format(num_wrong))
print(output_frame.to_string(index=False))

```


<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/8-t.mp4"></video>

**用感知器实现逻辑运算 - XOR （“异或”）**



![img](/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/8-i2.png)



**测验：构建一个 XOR 多层感知器**

现在我们使用 AND、NOT 和 OR 感知器构建一个多层感知器，以便创建 XOR 逻辑！

下面的神经网络包含三个感知器：A、B 和 C。最后一个 (AND) 已经提供给你了。神经网络的输入来自第一个节点。输出来自最后一个节点。

上面的多层感知器计算出 XOR。每个感知器都是 AND、OR 和 NOT 的逻辑运算。但是，感知器 A、B、C 和 D 并不表明它们的运算。在下面的测验中，请为四个感知器设置正确的运算，以便计算 XOR。



![img](/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/8-i3.png)

**习题 4/4**

在 XOR 神经网络中为感知器设置运算。

*Checkmark* These are the correct matches.

**感知器           运算符**

A                        AND

B                       OR

C                      NOT


## 9、为何称为“神经网络”？

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/9-t.mp4"></video>

## 10、感知器技巧 - 计算机如何“学习”分类？
感知器技巧 - 计算机如何“学习”分类？
在上一部分，你使用你自己的逻辑和数学知识为某些最常见的逻辑运算符创建了感知器。 但是在现实生活中，除了这些非常简单的形式，我们人类是无法靠自己构建这些感知器函数，找到用于分类的曲线的。

下面的视频将告诉你，计算机如何根据我们人类给出的结果，来自己进行构建感知器函数。对于这一点，有一个非常棒的技巧能帮到我们。

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/10-t.mp4"></video>

![img](/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/10-i1.png)



### 练习题

被错误分类的点，希望斜线离自己更近，还是更远？

- 更近
- 更远



<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/11-t.mp4"></video>

整个数据集中的每一个点都会把分类的结果提供给感知器（分类函数），并调整感知器。——这就是计算机在神经网络算法中，找寻最优感知器的原理。


## 11、感知器算法

掌握了感知器技巧后，我们就可以编写完整的感知器运算的算法了！

下面的视频将介绍感知器算法的伪代码，现在你还不需要担心什么是学习速率（learning rate），我们在之后的课程中会详细介绍为什么这里的伪代码中有学习率。

在视频下面的测验中，你将有机会用 Python 将其编成代码，并看看自己的感知器分类成果。加油！
<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/12-t.mp4"></video>

**编写感知器算法**

该编写代码了！在此练习中，你将实现感知器算法以分类下面的数据（位于文件 data.csv 中）。



![img](/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/11-i1.png)



感知器步骤如下所示。对于坐标轴为 (p,q)(p,q) 的点，标签 y，以及等式 $$\hat{y} = step(w_1x_1 + w_2x_2 + b)y^=step(w1x1+w2x2+b) $$

给出的预测

- 如果点分类正确，则什么也不做。
- 如果点分类为正，但是标签为负，则分别减去 $$\alpha p, \alpha q,αp,αq, $$和 $$\alphaα$$ 至$$ w_1, w_2,w1,w2,$$ 和$$ bb$$
- 如果点分类为负，但是标签为正，则分别将 $$\alpha p, \alpha q,αp,αq,$$ 和 $$\alphaα $$加到$$ w_1, w_2,w1,w2, $$和 $$bb$$ 上。

然后点击`测试运行`绘出感知器算法给出的解决方案。它实际上会画出一组虚线，显示算法如何接近最佳解决方案（用黑色实线表示）。

请随意改动算法的参数（epoch 数量、学习速率，甚至随机化初始参数），看看初始条件对解决方案有何影响！



```python
import numpy as np
# Setting the random seed, feel free to change it and see different solutions.
np.random.seed(42)

def stepFunction(t):
    if t >= 0:
        return 1
    return 0

def prediction(X, W, b):
    return stepFunction((np.matmul(X,W)+b)[0])

# TODO: Fill in the code below to implement the perceptron trick.
# The function should receive as inputs the data X, the labels y,
# the weights W (as an array), and the bias b,
# update the weights and bias W, b, according to the perceptron algorithm,
# and return W and b.
def perceptronStep(X, y, W, b, learn_rate = 0.01):
    # Fill in code
    return W, b
    
# This function runs the perceptron algorithm repeatedly on the dataset,
# and returns a few of the boundary lines obtained in the iterations,
# for plotting purposes.
# Feel free to play with the learning rate and the num_epochs,
# and see your results plotted below.
def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):
    x_min, x_max = min(X.T[0]), max(X.T[0])
    y_min, y_max = min(X.T[1]), max(X.T[1])
    W = np.array(np.random.rand(2,1))
    b = np.random.rand(1)[0] + x_max
    # These are the solution lines that get plotted below.
    boundary_lines = []
    for i in range(num_epochs):
        # In each epoch, we apply the perceptron step.
        W, b = perceptronStep(X, y, W, b, learn_rate)
        boundary_lines.append((-W[0]/W[1], -b/W[1]))
    return boundary_lines

```



```python
def perceptronStep(X, y, W, b, learn_rate = 0.01):
    for i in range(len(X)):
        y_hat = prediction(X[i],W,b)
        if y[i]-y_hat == 1:
            W[0] += X[i][0]*learn_rate
            W[1] += X[i][1]*learn_rate
            b += learn_rate
        elif y[i]-y_hat == -1:
            W[0] -= X[i][0]*learn_rate
            W[1] -= X[i][1]*learn_rate
            b -= learn_rate
    return W, b

```

[需要的数据](/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/11-1data.csv)





## 12、非线性界线

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/13-t.mp4"></video>-->

## 13、非线性界线
<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/14-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/15-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/16-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/17-t.mp4"></video>

<!--<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/18-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/19-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/20-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/21-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/22-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/23-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/24-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/25-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/26-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/27-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/28-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/29-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/30-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/31-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/32-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/33-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/34-t.mp4"></video>

<video src="/Users/weixu/github/hetaodie.github.io/assets/media/uda-ml/deep/sd/35-t.mp4"></video>-->